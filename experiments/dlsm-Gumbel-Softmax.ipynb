{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DLSM Architecture Translation into TensorFlow - Attempt","metadata":{"papermill":{"duration":0.02865,"end_time":"2022-04-30T04:44:07.927547","exception":false,"start_time":"2022-04-30T04:44:07.898897","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Utility Imports","metadata":{"papermill":{"duration":0.026175,"end_time":"2022-04-30T04:44:07.982914","exception":false,"start_time":"2022-04-30T04:44:07.956739","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/emergentlang/emergent-lang')\n\nimport shapedata\nimport analyzeutil","metadata":{"execution":{"iopub.status.busy":"2022-05-01T07:46:32.318591Z","iopub.execute_input":"2022-05-01T07:46:32.318958Z","iopub.status.idle":"2022-05-01T07:46:34.257758Z","shell.execute_reply.started":"2022-05-01T07:46:32.318872Z","shell.execute_reply":"2022-05-01T07:46:34.257020Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Library Imports","metadata":{"papermill":{"duration":0.021786,"end_time":"2022-04-30T04:44:11.960571","exception":false,"start_time":"2022-04-30T04:44:11.938785","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers as L\nimport tensorflow as tf\nimport tensorflow\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"papermill":{"duration":6.163676,"end_time":"2022-04-30T04:44:18.146163","exception":false,"start_time":"2022-04-30T04:44:11.982487","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-01T07:46:34.259404Z","iopub.execute_input":"2022-05-01T07:46:34.259657Z","iopub.status.idle":"2022-05-01T07:46:39.211264Z","shell.execute_reply.started":"2022-05-01T07:46:34.259622Z","shell.execute_reply":"2022-05-01T07:46:39.210409Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def softmax(x):\n    return np.exp(x) / np.sum(np.exp(x))\n\ntau = 1\n\nsample = np.random.uniform(0, 1, size=10)\nplt.scatter(np.arange(10), softmax(sample))\nplt.show()\nplt.scatter(np.arange(10), softmax((np.log(sample) + np.random.gumbel(size=10))/tau))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T07:33:02.807492Z","iopub.execute_input":"2022-05-01T07:33:02.807800Z","iopub.status.idle":"2022-05-01T07:33:03.152079Z","shell.execute_reply.started":"2022-05-01T07:33:02.807768Z","shell.execute_reply":"2022-05-01T07:33:03.151082Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"## Model Definition","metadata":{"papermill":{"duration":0.021781,"end_time":"2022-04-30T04:44:18.190808","exception":false,"start_time":"2022-04-30T04:44:18.169027","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class GumbelSoftmax(L.Layer):\n    \n    def __init__(self, tau, **kwargs):\n        super().__init__(**kwargs)\n        self.tau = tau\n        self.softmax = L.Softmax()\n        \n    def gumbel(self, shape):\n        return -tf.math.log(-tf.math.log(tf.random.uniform(shape)))\n    \n    def call(self, x):\n        \n        return self.softmax((tf.math.log(x) + self.gumbel(x.shape))/self.tau)\n        \n        # return tf.random.categorical(tf.math.log(x), 1)\n\nclass VectorQuantizer(L.Layer):\n    def __init__(self, vocab_size, seq_len, **kwargs):\n        super().__init__(**kwargs)\n        self.vocab_size = vocab_size\n        self.seq_len = seq_len\n        self.gumbelSoftmax = GumbelSoftmax(1)\n\n    def call(self, x):\n        # symbols = tf.math.argmax(x, axis=2)\n        \n        quantized = L.TimeDistributed(self.gumbelSoftmax)(x)\n        \n        # quantized = tf.one_hot(symbols, self.vocab_size)\n        \n        # quantized = x + tf.stop_gradient(quantized - x)\n        \n        return quantized\n\n\n\nclass DLSM(tf.keras.Model):\n\n    def __init__(self, \n                 inp_shape,           # the dimension of the image in three-element tuple form\n                 seq_len=16,          # number of vectors to form a language sequence\n                 vocab_size=32,       # number of unique vectors in vector quantizer\n                 recurrent_units=32,  # number of gru units, also embedding dim for now\n                 batch_size=32):      # number of samples per batch\n        \n        super().__init__()\n        \n        # structural params\n        self.batch_size = batch_size\n        self.inp_shape = inp_shape\n        self.seq_len = seq_len\n        self.vocab_size = vocab_size\n        self.recurrent_units = recurrent_units\n        \n        # model components\n        self.vision_module = self.buildVisionModule(inp_shape)\n        self.speaker = self.buildSpeaker((self.seq_len, 1))\n        self.quantizer = VectorQuantizer(self.vocab_size, self.seq_len)\n        self.listener = self.buildListener((self.seq_len, self.vocab_size))\n        \n        # misc\n        self.initial_speech = K.variable(value=np.zeros((self.batch_size, self.seq_len, 1)))\n    \n    def buildVisionModule(self, inp_shape):\n        '''\n        Vision Module - maps images to a vector with length recurrent_units.\n        '''\n        \n        model = keras.models.Sequential(name='Vision_Module')\n        model.add(L.Input(inp_shape))\n\n        model.add(L.Conv2D(16, (2, 5), padding='same'))\n        model.add(L.LeakyReLU())\n        model.add(L.Conv2D(16, (2, 5), padding='same'))\n        model.add(L.LeakyReLU())\n        model.add(L.Conv2D(16, (2, 2), padding='same'))\n        model.add(L.LeakyReLU())\n        model.add(L.MaxPooling2D((2, 2)))\n\n        model.add(L.Conv2D(16, (5, 2), padding='same'))\n        model.add(L.LeakyReLU())\n        model.add(L.Conv2D(16, (2, 5), padding='same'))\n        model.add(L.LeakyReLU())\n        model.add(L.Conv2D(16, (2, 2), padding='same'))\n        model.add(L.LeakyReLU())\n        model.add(L.MaxPooling2D((2, 2)))\n\n        model.add(L.Flatten())\n#         model.add(L.Dense(self.recurrent_units, activation='relu'))\n        model.add(L.Dense(self.recurrent_units, activation='relu'))\n        model.add(L.BatchNormalization())\n        \n        return model\n        \n    def buildSpeaker(self, inp_shape):\n        '''\n        Speaker - takes in initial speech vector and uses image\n        vector as initial hidden state. Outputs a sequence of vectors\n        that are quantized.\n        '''\n        \n        init_speech = L.Input(inp_shape)\n        init_cell = L.Input((self.recurrent_units,))\n        init_hidden = L.Input((self.recurrent_units,))\n        \n        processed_init_speech = L.TimeDistributed(L.Dense(self.recurrent_units, activation=\"relu\"))(init_speech)\n        processed_init_cell = L.Dense(self.recurrent_units, activation=\"relu\")(init_cell)\n        processed_init_hidden = L.Dense(self.recurrent_units, activation=\"relu\")(init_hidden)\n        \n        lstm1 = L.LSTM(self.recurrent_units, return_sequences=True)(processed_init_speech, initial_state=[processed_init_hidden, processed_init_cell])\n        \n        lstm2 = L.LSTM(self.recurrent_units, return_sequences=True)(lstm1, initial_state=[processed_init_hidden, processed_init_cell])\n        \n        output = L.TimeDistributed(L.Dense(self.vocab_size, activation=\"softmax\"))(lstm2)\n        \n        return keras.models.Model(inputs={'init_speech':init_speech, \n                                          'init_cell':init_cell,\n                                          'init_hidden':init_hidden},\n                                  outputs=output)\n\n    def buildListener(self, inp_shape):\n        '''\n        Listener - takes in the quantized 'language' and outputs a single\n        scalar probability.\n        '''\n        \n        init_speech = L.Input(inp_shape)\n        init_cell = L.Input((self.recurrent_units,))\n        init_hidden = L.Input((self.recurrent_units,))\n        \n        processed_init_speech = L.TimeDistributed(L.Dense(self.recurrent_units, activation=\"relu\"))(init_speech)\n        processed_init_cell = L.Dense(self.recurrent_units, activation=\"relu\")(init_cell)\n        processed_init_hidden = L.Dense(self.recurrent_units, activation=\"relu\")(init_hidden)\n        \n        lstm1 = L.LSTM(self.recurrent_units, return_sequences=True)(processed_init_speech, initial_state=[processed_init_hidden, processed_init_cell])\n        \n        lstm2 = L.LSTM(self.recurrent_units)(lstm1, initial_state=[processed_init_hidden, processed_init_cell])\n        \n        predense = L.Dense(32, activation='relu')(lstm2)\n        out = L.Dense(1, activation='sigmoid')(predense)\n        \n#         init_speech = L.Input(inp_shape)\n#         init_state = L.Input((self.recurrent_units,))\n#         gru = L.GRU(self.recurrent_units)(init_speech, initial_state=init_state)\n#         predense = L.Dense(32, activation='relu')(gru)\n#         out = L.Dense(1, activation='sigmoid')(predense)\n        \n        \n        return keras.models.Model(inputs=[init_speech, init_cell, init_hidden],\n                                  outputs=out)\n    \n    def get_sequence(self, inputs):\n        \n        # split data into half, Yegor-style\n        half = len(inputs) // 2\n        xa, xb = inputs[:half], inputs[half:]\n        \n        # get vision vectors\n        vision_a = self.vision_module(xa)\n        vision_b = self.vision_module(xb)\n        \n        # obtain spoken vectors {'init_speech':init_speech, 'init_state':init_state}\n        spoken_a = self.speaker({'init_speech':self.initial_speech,\n                                 'init_hidden':vision_a,# tf.random.normal((self.batch_size, self.recurrent_units,)),\n                                 'init_cell':vision_a})\n        spoken_b = self.speaker({'init_speech':self.initial_speech,\n                                 'init_hidden':vision_b,# tf.random.normal((self.batch_size, self.recurrent_units,)),\n                                 'init_cell':vision_b})\n        \n        return spoken_a, spoken_b\n        \n    \n    def call(self, inputs, training=True):\n        \n        # split data into half, Yegor-style\n        half = len(inputs) // 2\n        xa, xb = inputs[:half], inputs[half:]\n        \n        # get vision vectors\n        vision_a = self.vision_module(xa)\n        vision_b = self.vision_module(xb)\n        \n        # obtain spoken vectors {'init_speech':init_speech, 'init_state':init_state}\n        spoken_a = self.speaker({'init_speech':self.initial_speech,\n                                 'init_hidden':vision_a,# tf.random.normal((self.batch_size, self.recurrent_units,)),\n                                 'init_cell':vision_a})\n        spoken_b = self.speaker({'init_speech':self.initial_speech,\n                                 'init_hidden':vision_b,# tf.random.normal((self.batch_size, self.recurrent_units,)),\n                                 'init_cell':vision_b})\n        \n        # quantize speech\n        quantized_a = self.quantizer(spoken_a)\n        quantized_b = self.quantizer(spoken_b)\n        \n        # obtain output vectors after listening\n        listened_a = self.listener([quantized_a, vision_b, tf.random.normal((self.batch_size, self.recurrent_units,))])\n        listened_b = self.listener([quantized_b, vision_a, tf.random.normal((self.batch_size, self.recurrent_units,))])\n        \n        return listened_a, listened_b","metadata":{"papermill":{"duration":0.061477,"end_time":"2022-04-30T04:44:18.274141","exception":false,"start_time":"2022-04-30T04:44:18.212664","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-01T08:19:18.870058Z","iopub.execute_input":"2022-05-01T08:19:18.870324Z","iopub.status.idle":"2022-05-01T08:19:18.908264Z","shell.execute_reply.started":"2022-05-01T08:19:18.870295Z","shell.execute_reply":"2022-05-01T08:19:18.907466Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"papermill":{"duration":0.02158,"end_time":"2022-04-30T04:44:18.317408","exception":false,"start_time":"2022-04-30T04:44:18.295828","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import tensorflow.keras.backend as K\n\n'''\nCore data parameters\n'''\nBATCH_SIZE = 512\nSEQ_LEN = 3\nVOCAB_SIZE = 9\nRECURRENT_UNITS = 64\n\nIMG_DIM = 128\nMIN_SHAPES = 1\nMAX_SHAPES = 3\nSHAPE_TYPES = ['square', 'circle', 'triangle']\nCOLOR_TYPES = [(255,0,0), (0,255,  0), (0,0,255)]\nOUTLINE = (255, 255, 255)\nSHAPE_SCALE = 0.2\n\n# create dataset\ndata = shapedata.AlecModeShapeData(batch_size=BATCH_SIZE, \n                                   im_size=IMG_DIM, \n                                   min_shapes=MIN_SHAPES, \n                                   max_shapes=MAX_SHAPES,\n                                   outline = OUTLINE,\n                                   shape_types = SHAPE_TYPES,\n                                   shape_colors = COLOR_TYPES,\n                                   shape_scale = SHAPE_SCALE)\n\n# create relevant training artifacts\noptimizer = tensorflow.keras.optimizers.Adam(learning_rate=1e-3)\nbce = tensorflow.keras.losses.BinaryCrossentropy()\n# mse = tensorflow.keras.losses.MeanSquaredError()\nmodel = DLSM((IMG_DIM, IMG_DIM, 3), \n             seq_len=SEQ_LEN,\n             vocab_size=VOCAB_SIZE,\n             recurrent_units=RECURRENT_UNITS,\n             batch_size=BATCH_SIZE)\n\n# train batch function\n@tf.function\ndef train_batch(x, y):\n    with tf.GradientTape() as tape:\n        half = len(y) // 2\n        outa, outb = model(x, training=True)\n        \n        loss = tf.math.divide(tf.math.add(bce(y, outa), bce(y, outb)), 2) # use avg bce as loss\n#         acc = tf.math.divide(tf.math.add(acc(y, outa), acc(y, outb)), 2)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    return loss, (outa, outb, y)","metadata":{"papermill":{"duration":6.768488,"end_time":"2022-04-30T04:44:25.10753","exception":false,"start_time":"2022-04-30T04:44:18.339042","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-01T08:19:20.290428Z","iopub.execute_input":"2022-05-01T08:19:20.295036Z","iopub.status.idle":"2022-05-01T08:19:21.396503Z","shell.execute_reply.started":"2022-05-01T08:19:20.294137Z","shell.execute_reply":"2022-05-01T08:19:21.395738Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"shapedata.demo_dataset(data)","metadata":{"papermill":{"duration":0.159556,"end_time":"2022-04-30T04:44:25.291422","exception":false,"start_time":"2022-04-30T04:44:25.131866","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-01T08:19:21.403785Z","iopub.execute_input":"2022-05-01T08:19:21.403991Z","iopub.status.idle":"2022-05-01T08:19:21.513866Z","shell.execute_reply.started":"2022-05-01T08:19:21.403967Z","shell.execute_reply":"2022-05-01T08:19:21.512872Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score as acc\n\nNUM_EPOCHS = 100_000\n\nlosses, accs = [], []\nfor epoch in range(NUM_EPOCHS):\n    (x1, x1_shapes), (x2, x2_shapes), y = data.create_batch()\n    loss, (outa, outb, y) = train_batch(np.concatenate([x1, x2]), np.expand_dims(y,1))\n    loss = loss.numpy()\n    accuracy = (acc(np.round(outa), y) + acc(np.round(outb), y))/2\n    print(f'BATCH {epoch} | Loss: {loss} | Acc: {accuracy}', end = '\\r')\n    losses.append(loss)\n    accs.append(accuracy)\n\nplt.figure(figsize=(10, 5), dpi=400)\nplt.plot(losses, color='red')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show()\nplt.close()\n\nplt.figure(figsize=(10, 5), dpi=400)\nplt.plot(accs, color='red')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.show()\nplt.close()","metadata":{"papermill":{"duration":1471.777408,"end_time":"2022-04-30T05:08:57.09225","exception":false,"start_time":"2022-04-30T04:44:25.314842","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-01T08:19:22.248053Z","iopub.execute_input":"2022-05-01T08:19:22.248303Z","iopub.status.idle":"2022-05-01T17:35:37.759013Z","shell.execute_reply.started":"2022-05-01T08:19:22.248273Z","shell.execute_reply":"2022-05-01T17:35:37.755395Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5), dpi=400)\nplt.plot(losses, color='red')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\n\nplt.savefig(\"Losses.png\")\n\nplt.show()\nplt.close()\n\n\n\nplt.figure(figsize=(10, 5), dpi=400)\nplt.plot(accs, color='red')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\n\nplt.savefig(\"Accs.png\")\n\nplt.show()\nplt.close()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:40:22.142578Z","iopub.execute_input":"2022-05-01T17:40:22.143082Z","iopub.status.idle":"2022-05-01T17:40:25.325521Z","shell.execute_reply.started":"2022-05-01T17:40:22.143046Z","shell.execute_reply":"2022-05-01T17:40:25.324836Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# model.load_weights('weights.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:44:35.008947Z","iopub.status.idle":"2022-04-30T21:44:35.00965Z","shell.execute_reply.started":"2022-04-30T21:44:35.009361Z","shell.execute_reply":"2022-04-30T21:44:35.009389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```\nBATCH 1999 | Loss: 0.3106675446033478 | Acc: 0.880859375\n```","metadata":{"papermill":{"duration":0.621547,"end_time":"2022-04-30T05:08:58.382606","exception":false,"start_time":"2022-04-30T05:08:57.761059","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model.save_weights('weights.h5')","metadata":{"papermill":{"duration":0.674519,"end_time":"2022-04-30T05:08:59.681274","exception":false,"start_time":"2022-04-30T05:08:59.006755","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-01T17:35:47.475702Z","iopub.execute_input":"2022-05-01T17:35:47.475958Z","iopub.status.idle":"2022-05-01T17:35:47.526089Z","shell.execute_reply.started":"2022-05-01T17:35:47.475928Z","shell.execute_reply":"2022-05-01T17:35:47.525292Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# x = np.linspace(-5, 5, 1000)\n# y = np.sin(x)\n# plt.plot(x, y)\n# plt.title('$\\sin x$')\n# plt.xlabel('time')\n# plt.ylabel('my iq')\n# plt.show()\n\n# x = np.linspace(-5, 5, 1000)\n# y = np.sin(x)\n# plt.figure(dpi=500)\n# plt.plot(x, y)\n# plt.title('better plot of $\\sin x$')\n# plt.xlabel('time')\n# plt.ylabel('my iq')\n# plt.show()","metadata":{"execution":{"iopub.execute_input":"2022-04-30T05:09:00.934358Z","iopub.status.busy":"2022-04-30T05:09:00.933542Z","iopub.status.idle":"2022-04-30T05:09:00.935555Z","shell.execute_reply":"2022-04-30T05:09:00.935964Z","shell.execute_reply.started":"2022-04-30T01:02:56.895277Z"},"papermill":{"duration":0.628899,"end_time":"2022-04-30T05:09:00.936101","exception":false,"start_time":"2022-04-30T05:09:00.307202","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testdata = shapedata.AlecModeShapeData(batch_size=BATCH_SIZE, \n                               im_size=IMG_DIM, \n                               min_shapes=MIN_SHAPES, \n                               max_shapes=MAX_SHAPES,\n                               outline = OUTLINE,\n                               shape_types = SHAPE_TYPES,\n                               shape_colors = COLOR_TYPES,\n                               shape_scale = SHAPE_SCALE)\n(x1, x1_shapes), (x2, x2_shapes), y = testdata.create_batch()","metadata":{"papermill":{"duration":0.742651,"end_time":"2022-04-30T05:09:02.30231","exception":false,"start_time":"2022-04-30T05:09:01.559659","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-01T17:37:47.994612Z","iopub.execute_input":"2022-05-01T17:37:47.994868Z","iopub.status.idle":"2022-05-01T17:37:48.076403Z","shell.execute_reply.started":"2022-05-01T17:37:47.994839Z","shell.execute_reply":"2022-05-01T17:37:48.075648Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"speecha, speechb = model.get_sequence(np.concatenate([x1, x2]))","metadata":{"papermill":{"duration":0.833356,"end_time":"2022-04-30T05:09:03.758922","exception":false,"start_time":"2022-04-30T05:09:02.925566","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-01T17:37:49.544384Z","iopub.execute_input":"2022-05-01T17:37:49.545140Z","iopub.status.idle":"2022-05-01T17:37:49.741126Z","shell.execute_reply.started":"2022-05-01T17:37:49.545098Z","shell.execute_reply":"2022-05-01T17:37:49.738643Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-05-01T17:37:52.750101Z","iopub.execute_input":"2022-05-01T17:37:52.750924Z","iopub.status.idle":"2022-05-01T17:37:52.754709Z","shell.execute_reply.started":"2022-05-01T17:37:52.750881Z","shell.execute_reply":"2022-05-01T17:37:52.753955Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"quant = model.quantizer(speecha)\n\n# seqs = model.quantizer(quant)\n\n# seqs = np.array(seqs)\n# seqs = np.argmax(seqs, axis=2)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-05-01T17:38:32.201670Z","iopub.execute_input":"2022-05-01T17:38:32.202197Z","iopub.status.idle":"2022-05-01T17:38:32.218138Z","shell.execute_reply.started":"2022-05-01T17:38:32.202164Z","shell.execute_reply":"2022-05-01T17:38:32.217479Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"plt.plot(quant[3, 0].numpy())","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:43:28.413189Z","iopub.execute_input":"2022-05-01T17:43:28.413748Z","iopub.status.idle":"2022-05-01T17:43:28.595541Z","shell.execute_reply.started":"2022-05-01T17:43:28.413705Z","shell.execute_reply":"2022-05-01T17:43:28.594865Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"print(speecha[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:56:40.761679Z","iopub.execute_input":"2022-04-30T22:56:40.762019Z","iopub.status.idle":"2022-04-30T22:56:40.774242Z","shell.execute_reply.started":"2022-04-30T22:56:40.761982Z","shell.execute_reply":"2022-04-30T22:56:40.773226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(seqs, axis=0)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-04-30T22:41:30.961318Z","iopub.execute_input":"2022-04-30T22:41:30.961972Z","iopub.status.idle":"2022-04-30T22:41:30.968473Z","shell.execute_reply.started":"2022-04-30T22:41:30.961928Z","shell.execute_reply":"2022-04-30T22:41:30.96765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, seq in enumerate(seqs):\n    if (seq==[7,7,7]).all():\n        plt.imshow(x1[i])\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T20:17:02.074252Z","iopub.execute_input":"2022-04-30T20:17:02.074926Z","iopub.status.idle":"2022-04-30T20:17:16.401096Z","shell.execute_reply.started":"2022-04-30T20:17:02.074884Z","shell.execute_reply":"2022-04-30T20:17:16.400347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.argwhere(seqs==[7, 7, 7]))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T20:10:28.148822Z","iopub.execute_input":"2022-04-30T20:10:28.149577Z","iopub.status.idle":"2022-04-30T20:10:28.160151Z","shell.execute_reply.started":"2022-04-30T20:10:28.149538Z","shell.execute_reply":"2022-04-30T20:10:28.159359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(np.unique(seqs, axis=0))","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-04-30T20:08:57.286655Z","iopub.execute_input":"2022-04-30T20:08:57.287384Z","iopub.status.idle":"2022-04-30T20:08:57.293249Z","shell.execute_reply.started":"2022-04-30T20:08:57.287337Z","shell.execute_reply":"2022-04-30T20:08:57.292587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a, b = pred = model(np.concatenate([x1, x2]))\npred = (a + b)/2\n\nprint('CORRECT')\n\nfor i in range(len(x2)):\n    \n    if np.round(pred[i]) != np.round(y[i]):\n\n        plt.figure(figsize=(10, 5), dpi=400)\n        plt.subplot(1, 2, 1)\n        plt.imshow(x1[i])\n        plt.axis('off')\n        plt.title(f'Pred: {pred[i]}')\n        plt.subplot(1, 2, 2)\n        plt.imshow(x2[i])\n        plt.axis('off')\n        plt.title(f'Truth: {y[i]}')\n        plt.show()\n        plt.close()\n        \n        \n        \nprint('-'*500)\nprint('CORRECT')\n\nfor i in range(len(x2)):\n    \n    if np.round(pred[i]) == np.round(y[i]):\n\n        plt.figure(figsize=(10, 5), dpi=400)\n        plt.subplot(1, 2, 1)\n        plt.imshow(x1[i])\n        plt.axis('off')\n        plt.title(f'Pred: {pred[i]}')\n        plt.subplot(1, 2, 2)\n        plt.imshow(x2[i])\n        plt.axis('off')\n        plt.title(f'Truth: {y[i]}')\n        plt.show()\n        plt.close()","metadata":{"execution":{"iopub.execute_input":"2022-04-30T01:04:46.628144Z","iopub.status.busy":"2022-04-30T01:04:46.627791Z","iopub.status.idle":"2022-04-30T01:05:09.021065Z","shell.execute_reply":"2022-04-30T01:05:09.020286Z","shell.execute_reply.started":"2022-04-30T01:04:46.628107Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]}]}