{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DLSM Architecture Translation into TensorFlow - Attempt","metadata":{"papermill":{"duration":0.02865,"end_time":"2022-04-30T04:44:07.927547","exception":false,"start_time":"2022-04-30T04:44:07.898897","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Utility Imports","metadata":{"papermill":{"duration":0.026175,"end_time":"2022-04-30T04:44:07.982914","exception":false,"start_time":"2022-04-30T04:44:07.956739","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/emergentlang/emergent-lang')\n\nimport shapedata\nimport analyzeutil","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:33:42.244657Z","iopub.execute_input":"2022-04-30T21:33:42.245568Z","iopub.status.idle":"2022-04-30T21:33:43.911036Z","shell.execute_reply.started":"2022-04-30T21:33:42.245441Z","shell.execute_reply":"2022-04-30T21:33:43.910215Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Library Imports","metadata":{"papermill":{"duration":0.021786,"end_time":"2022-04-30T04:44:11.960571","exception":false,"start_time":"2022-04-30T04:44:11.938785","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers as L\nimport tensorflow as tf\nimport tensorflow\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"papermill":{"duration":6.163676,"end_time":"2022-04-30T04:44:18.146163","exception":false,"start_time":"2022-04-30T04:44:11.982487","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-30T21:33:47.900357Z","iopub.execute_input":"2022-04-30T21:33:47.900962Z","iopub.status.idle":"2022-04-30T21:33:52.525320Z","shell.execute_reply.started":"2022-04-30T21:33:47.900919Z","shell.execute_reply":"2022-04-30T21:33:52.524533Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Model Definition","metadata":{"papermill":{"duration":0.021781,"end_time":"2022-04-30T04:44:18.190808","exception":false,"start_time":"2022-04-30T04:44:18.169027","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class Categorical(L.Layer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n    def call(self, x):\n        return tf.random.categorical(tf.math.log(x), 1)\n\nclass VectorQuantizer(L.Layer):\n    def __init__(self, vocab_size, seq_len, **kwargs):\n        super().__init__(**kwargs)\n        self.vocab_size = vocab_size\n        self.seq_len = seq_len\n        self.categorical = Categorical()\n\n    def call(self, x):\n        symbols = tf.math.argmax(x, axis=2)\n        \n        symbols = L.TimeDistributed(self.categorical)(x)\n        \n        symbols = L.Reshape((self.seq_len,))(symbols)\n        \n        quantized = tf.one_hot(symbols, self.vocab_size)\n        quantized = x + tf.stop_gradient(quantized - x)\n        return quantized\n\n\n\nclass DLSM(tf.keras.Model):\n\n    def __init__(self, \n                 inp_shape,           # the dimension of the image in three-element tuple form\n                 seq_len=16,          # number of vectors to form a language sequence\n                 vocab_size=32,       # number of unique vectors in vector quantizer\n                 recurrent_units=32,  # number of gru units, also embedding dim for now\n                 batch_size=32):      # number of samples per batch\n        \n        super().__init__()\n        \n        # structural params\n        self.batch_size = batch_size\n        self.inp_shape = inp_shape\n        self.seq_len = seq_len\n        self.vocab_size = vocab_size\n        self.recurrent_units = recurrent_units\n        \n        # model components\n        self.vision_module = self.buildVisionModule(inp_shape)\n        self.speaker = self.buildSpeaker((self.seq_len, 1))\n        self.quantizer = VectorQuantizer(self.vocab_size, self.seq_len)\n        self.listener = self.buildListener((self.seq_len, self.vocab_size))\n        \n        # misc\n        self.initial_speech = K.variable(value=np.zeros((self.batch_size, self.seq_len, 1)))\n    \n    def buildVisionModule(self, inp_shape):\n        '''\n        Vision Module - maps images to a vector with length recurrent_units.\n        '''\n        \n        model = keras.models.Sequential(name='Vision_Module')\n        model.add(L.Input(inp_shape))\n\n        model.add(L.Conv2D(16, (2, 5), padding='same'))\n        model.add(L.LeakyReLU())\n        model.add(L.Conv2D(16, (2, 5), padding='same'))\n        model.add(L.LeakyReLU())\n        model.add(L.Conv2D(16, (2, 2), padding='same'))\n        model.add(L.LeakyReLU())\n        model.add(L.MaxPooling2D((2, 2)))\n\n        model.add(L.Conv2D(16, (5, 2), padding='same'))\n        model.add(L.LeakyReLU())\n        model.add(L.Conv2D(16, (2, 5), padding='same'))\n        model.add(L.LeakyReLU())\n        model.add(L.Conv2D(16, (2, 2), padding='same'))\n        model.add(L.LeakyReLU())\n        model.add(L.MaxPooling2D((2, 2)))\n\n        model.add(L.Flatten())\n#         model.add(L.Dense(self.recurrent_units, activation='relu'))\n        model.add(L.Dense(self.recurrent_units, activation='relu'))\n        model.add(L.BatchNormalization())\n        \n        return model\n        \n    def buildSpeaker(self, inp_shape):\n        '''\n        Speaker - takes in initial speech vector and uses image\n        vector as initial hidden state. Outputs a sequence of vectors\n        that are quantized.\n        '''\n        \n        init_speech = L.Input(inp_shape)\n        init_cell = L.Input((self.recurrent_units,))\n        init_hidden = L.Input((self.recurrent_units,))\n        \n        processed_init_cell = L.Dense(self.recurrent_units, activation=\"relu\")(init_cell)\n        processed_init_hidden = L.Dense(self.recurrent_units, activation=\"relu\")(init_hidden)\n        \n        lstm1 = L.Bidirectional(L.LSTM(self.recurrent_units, return_sequences=True),\n                                merge_mode='sum')(init_speech, initial_state=[processed_init_hidden, processed_init_cell,\n                                                                              processed_init_hidden, processed_init_cell])\n        lstm2 = L.Bidirectional(L.LSTM(self.recurrent_units, return_sequences=True),\n                                merge_mode='sum')(lstm1, initial_state=[processed_init_hidden, processed_init_cell,\n                                                                        processed_init_hidden, processed_init_cell])\n        \n        output = L.TimeDistributed(L.Dense(self.vocab_size, activation=\"softmax\"))(lstm2)\n        \n        return keras.models.Model(inputs={'init_speech':init_speech, \n                                          'init_cell':init_cell,\n                                          'init_hidden':init_hidden},\n                                  outputs=output)\n\n    def buildListener(self, inp_shape):\n        '''\n        Listener - takes in the quantized 'language' and outputs a single\n        scalar probability.\n        '''\n        \n        init_speech = L.Input(inp_shape)\n        init_cell = L.Input((self.recurrent_units,))\n        init_hidden = L.Input((self.recurrent_units,))\n        \n        processed_init_speech = L.TimeDistributed(L.Dense(self.recurrent_units))(init_speech)\n        processed_init_cell = L.Dense(self.recurrent_units, activation=\"relu\")(init_cell)\n        processed_init_hidden = L.Dense(self.recurrent_units, activation=\"relu\")(init_hidden)\n        \n        lstm1 = L.Bidirectional(L.LSTM(self.recurrent_units, return_sequences=True),\n                                merge_mode='sum')(processed_init_speech, initial_state=[processed_init_hidden, processed_init_cell,\n                                                                              processed_init_hidden, processed_init_cell])\n        lstm3 = L.Bidirectional(L.LSTM(self.recurrent_units),\n                                merge_mode='sum')(lstm1, initial_state=[processed_init_hidden, processed_init_cell,\n                                                                        processed_init_hidden, processed_init_cell])\n        \n        predense = L.Dense(32, activation='relu')(lstm3)\n        out = L.Dense(1, activation='sigmoid')(predense)\n        \n#         init_speech = L.Input(inp_shape)\n#         init_state = L.Input((self.recurrent_units,))\n#         gru = L.GRU(self.recurrent_units)(init_speech, initial_state=init_state)\n#         predense = L.Dense(32, activation='relu')(gru)\n#         out = L.Dense(1, activation='sigmoid')(predense)\n        \n        \n        return keras.models.Model(inputs=[init_speech, init_cell, init_hidden],\n                                  outputs=out)\n    \n    def get_sequence(self, inputs):\n        \n        # split data into half, Yegor-style\n        half = len(inputs) // 2\n        xa, xb = inputs[:half], inputs[half:]\n        \n        # get vision vectors\n        vision_a = self.vision_module(xa)\n        vision_b = self.vision_module(xb)\n        \n        # obtain spoken vectors {'init_speech':init_speech, 'init_state':init_state}\n        spoken_a = self.speaker({'init_speech':self.initial_speech,\n                                 'init_hidden':vision_a,# tf.random.normal((self.batch_size, self.recurrent_units,)),\n                                 'init_cell':vision_a})\n        spoken_b = self.speaker({'init_speech':self.initial_speech,\n                                 'init_hidden':vision_b,# tf.random.normal((self.batch_size, self.recurrent_units,)),\n                                 'init_cell':vision_b})\n        \n        return spoken_a, spoken_b\n        \n    \n    def call(self, inputs, training=True):\n        \n        # split data into half, Yegor-style\n        half = len(inputs) // 2\n        xa, xb = inputs[:half], inputs[half:]\n        \n        # get vision vectors\n        vision_a = self.vision_module(xa)\n        vision_b = self.vision_module(xb)\n        \n        # obtain spoken vectors {'init_speech':init_speech, 'init_state':init_state}\n        spoken_a = self.speaker({'init_speech':self.initial_speech,\n                                 'init_hidden':vision_a,# tf.random.normal((self.batch_size, self.recurrent_units,)),\n                                 'init_cell':vision_a})\n        spoken_b = self.speaker({'init_speech':self.initial_speech,\n                                 'init_hidden':vision_b,# tf.random.normal((self.batch_size, self.recurrent_units,)),\n                                 'init_cell':vision_b})\n        \n        # quantize speech\n        quantized_a = self.quantizer(spoken_a)\n        quantized_b = self.quantizer(spoken_b)\n        \n        # obtain output vectors after listening\n        listened_a = self.listener([quantized_a, vision_b, tf.random.normal((self.batch_size, self.recurrent_units,))])\n        listened_b = self.listener([quantized_b, vision_a, tf.random.normal((self.batch_size, self.recurrent_units,))])\n        \n        return listened_a, listened_b","metadata":{"papermill":{"duration":0.061477,"end_time":"2022-04-30T04:44:18.274141","exception":false,"start_time":"2022-04-30T04:44:18.212664","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-30T22:07:38.029861Z","iopub.execute_input":"2022-04-30T22:07:38.030506Z","iopub.status.idle":"2022-04-30T22:07:38.071753Z","shell.execute_reply.started":"2022-04-30T22:07:38.030454Z","shell.execute_reply":"2022-04-30T22:07:38.070896Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"papermill":{"duration":0.02158,"end_time":"2022-04-30T04:44:18.317408","exception":false,"start_time":"2022-04-30T04:44:18.295828","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import tensorflow.keras.backend as K\n\n'''\nCore data parameters\n'''\nBATCH_SIZE = 512\nSEQ_LEN = 3\nVOCAB_SIZE = 9\nRECURRENT_UNITS = 64\n\nIMG_DIM = 128\nMIN_SHAPES = 1\nMAX_SHAPES = 3\nSHAPE_TYPES = ['square', 'circle', 'triangle']\nCOLOR_TYPES = [(255,0,0), (0,255,  0), (0,0,255)]\nOUTLINE = (255, 255, 255)\nSHAPE_SCALE = 0.2\n\n# create dataset\ndata = shapedata.AlecModeShapeData(batch_size=BATCH_SIZE, \n                                   im_size=IMG_DIM, \n                                   min_shapes=MIN_SHAPES, \n                                   max_shapes=MAX_SHAPES,\n                                   outline = OUTLINE,\n                                   shape_types = SHAPE_TYPES,\n                                   shape_colors = COLOR_TYPES,\n                                   shape_scale = SHAPE_SCALE)\n\n# create relevant training artifacts\noptimizer = tensorflow.keras.optimizers.Adam(learning_rate=1e-3)\nbce = tensorflow.keras.losses.BinaryCrossentropy()\n# mse = tensorflow.keras.losses.MeanSquaredError()\nmodel = DLSM((IMG_DIM, IMG_DIM, 3), \n             seq_len=SEQ_LEN,\n             vocab_size=VOCAB_SIZE,\n             recurrent_units=RECURRENT_UNITS,\n             batch_size=BATCH_SIZE)\n\n# train batch function\n@tf.function\ndef train_batch(x, y):\n    with tf.GradientTape() as tape:\n        half = len(y) // 2\n        outa, outb = model(x, training=True)\n        \n        loss = tf.math.divide(tf.math.add(bce(y, outa), bce(y, outb)), 2) # use avg bce as loss\n#         acc = tf.math.divide(tf.math.add(acc(y, outa), acc(y, outb)), 2)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    return loss, (outa, outb, y)","metadata":{"papermill":{"duration":6.768488,"end_time":"2022-04-30T04:44:25.107530","exception":false,"start_time":"2022-04-30T04:44:18.339042","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-30T22:07:39.965909Z","iopub.execute_input":"2022-04-30T22:07:39.966665Z","iopub.status.idle":"2022-04-30T22:07:42.096671Z","shell.execute_reply.started":"2022-04-30T22:07:39.966627Z","shell.execute_reply":"2022-04-30T22:07:42.095784Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"shapedata.demo_dataset(data)","metadata":{"papermill":{"duration":0.159556,"end_time":"2022-04-30T04:44:25.291422","exception":false,"start_time":"2022-04-30T04:44:25.131866","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-30T22:09:33.184289Z","iopub.execute_input":"2022-04-30T22:09:33.184752Z","iopub.status.idle":"2022-04-30T22:09:33.336275Z","shell.execute_reply.started":"2022-04-30T22:09:33.184713Z","shell.execute_reply":"2022-04-30T22:09:33.335329Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score as acc\n\nNUM_EPOCHS = 2000\n\nlosses, accs = [], []\nfor epoch in range(NUM_EPOCHS):\n    (x1, x1_shapes), (x2, x2_shapes), y = data.create_batch()\n    loss, (outa, outb, y) = train_batch(np.concatenate([x1, x2]), np.expand_dims(y,1))\n    loss = loss.numpy()\n    accuracy = (acc(np.round(outa), y) + acc(np.round(outb), y))/2\n    print(f'BATCH {epoch} | Loss: {loss} | Acc: {accuracy}', end = '\\r')\n    losses.append(loss)\n    accs.append(accuracy)\n    \n# plt.figure(figsize=(10, 5), dpi=400)\n# plt.plot(losses, color='red')\n# plt.xlabel('Epoch')\n# plt.ylabel('Loss')\n# plt.show()\n# plt.close()\n\n# plt.figure(figsize=(10, 5), dpi=400)\n# plt.plot(accs, color='red')\n# plt.xlabel('Epoch')\n# plt.ylabel('Accuracy')\n# plt.show()\n# plt.close()","metadata":{"papermill":{"duration":1471.777408,"end_time":"2022-04-30T05:08:57.092250","exception":false,"start_time":"2022-04-30T04:44:25.314842","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-30T22:09:34.061972Z","iopub.execute_input":"2022-04-30T22:09:34.062252Z","iopub.status.idle":"2022-04-30T22:34:17.068184Z","shell.execute_reply.started":"2022-04-30T22:09:34.062219Z","shell.execute_reply":"2022-04-30T22:34:17.067175Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"model.load_weights('weights.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:44:35.008947Z","iopub.status.idle":"2022-04-30T21:44:35.009650Z","shell.execute_reply.started":"2022-04-30T21:44:35.009361Z","shell.execute_reply":"2022-04-30T21:44:35.009389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```\nBATCH 1999 | Loss: 0.3106675446033478 | Acc: 0.880859375\n```","metadata":{"papermill":{"duration":0.621547,"end_time":"2022-04-30T05:08:58.382606","exception":false,"start_time":"2022-04-30T05:08:57.761059","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model.save_weights('weights.h5')","metadata":{"papermill":{"duration":0.674519,"end_time":"2022-04-30T05:08:59.681274","exception":false,"start_time":"2022-04-30T05:08:59.006755","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-30T20:07:54.107529Z","iopub.execute_input":"2022-04-30T20:07:54.107787Z","iopub.status.idle":"2022-04-30T20:07:54.171433Z","shell.execute_reply.started":"2022-04-30T20:07:54.107759Z","shell.execute_reply":"2022-04-30T20:07:54.170580Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# x = np.linspace(-5, 5, 1000)\n# y = np.sin(x)\n# plt.plot(x, y)\n# plt.title('$\\sin x$')\n# plt.xlabel('time')\n# plt.ylabel('my iq')\n# plt.show()\n\n# x = np.linspace(-5, 5, 1000)\n# y = np.sin(x)\n# plt.figure(dpi=500)\n# plt.plot(x, y)\n# plt.title('better plot of $\\sin x$')\n# plt.xlabel('time')\n# plt.ylabel('my iq')\n# plt.show()","metadata":{"execution":{"iopub.execute_input":"2022-04-30T05:09:00.934358Z","iopub.status.busy":"2022-04-30T05:09:00.933542Z","iopub.status.idle":"2022-04-30T05:09:00.935555Z","shell.execute_reply":"2022-04-30T05:09:00.935964Z","shell.execute_reply.started":"2022-04-30T01:02:56.895277Z"},"papermill":{"duration":0.628899,"end_time":"2022-04-30T05:09:00.936101","exception":false,"start_time":"2022-04-30T05:09:00.307202","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testdata = shapedata.AlecModeShapeData(batch_size=BATCH_SIZE, \n                               im_size=IMG_DIM, \n                               min_shapes=MIN_SHAPES, \n                               max_shapes=MAX_SHAPES,\n                               outline = OUTLINE,\n                               shape_types = SHAPE_TYPES,\n                               shape_colors = COLOR_TYPES,\n                               shape_scale = SHAPE_SCALE)\n(x1, x1_shapes), (x2, x2_shapes), y = testdata.create_batch()","metadata":{"papermill":{"duration":0.742651,"end_time":"2022-04-30T05:09:02.302310","exception":false,"start_time":"2022-04-30T05:09:01.559659","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-30T22:40:20.915514Z","iopub.execute_input":"2022-04-30T22:40:20.916369Z","iopub.status.idle":"2022-04-30T22:40:21.028133Z","shell.execute_reply.started":"2022-04-30T22:40:20.916330Z","shell.execute_reply":"2022-04-30T22:40:21.027318Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"speecha, speechb = model.get_sequence(np.concatenate([x1, x2]))","metadata":{"papermill":{"duration":0.833356,"end_time":"2022-04-30T05:09:03.758922","exception":false,"start_time":"2022-04-30T05:09:02.925566","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-30T22:40:22.049264Z","iopub.execute_input":"2022-04-30T22:40:22.049846Z","iopub.status.idle":"2022-04-30T22:40:22.292344Z","shell.execute_reply.started":"2022-04-30T22:40:22.049804Z","shell.execute_reply":"2022-04-30T22:40:22.291119Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-04-30T22:40:23.968976Z","iopub.execute_input":"2022-04-30T22:40:23.969265Z","iopub.status.idle":"2022-04-30T22:40:23.973814Z","shell.execute_reply.started":"2022-04-30T22:40:23.969232Z","shell.execute_reply":"2022-04-30T22:40:23.972848Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"quant = model.quantizer(speecha)\n\nseqs = model.quantizer(quant)\n\nseqs = np.array(seqs)\nseqs = np.argmax(seqs, axis=2)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-04-30T22:41:21.098115Z","iopub.execute_input":"2022-04-30T22:41:21.098405Z","iopub.status.idle":"2022-04-30T22:41:21.119099Z","shell.execute_reply.started":"2022-04-30T22:41:21.098372Z","shell.execute_reply":"2022-04-30T22:41:21.118363Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"np.unique(seqs, axis=0)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-04-30T22:41:30.961318Z","iopub.execute_input":"2022-04-30T22:41:30.961972Z","iopub.status.idle":"2022-04-30T22:41:30.968473Z","shell.execute_reply.started":"2022-04-30T22:41:30.961928Z","shell.execute_reply":"2022-04-30T22:41:30.967650Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"for i, seq in enumerate(seqs):\n    if (seq==[7,7,7]).all():\n        plt.imshow(x1[i])\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T20:17:02.074252Z","iopub.execute_input":"2022-04-30T20:17:02.074926Z","iopub.status.idle":"2022-04-30T20:17:16.401096Z","shell.execute_reply.started":"2022-04-30T20:17:02.074884Z","shell.execute_reply":"2022-04-30T20:17:16.400347Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print(np.argwhere(seqs==[7, 7, 7]))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T20:10:28.148822Z","iopub.execute_input":"2022-04-30T20:10:28.149577Z","iopub.status.idle":"2022-04-30T20:10:28.160151Z","shell.execute_reply.started":"2022-04-30T20:10:28.149538Z","shell.execute_reply":"2022-04-30T20:10:28.159359Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"len(np.unique(seqs, axis=0))","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-04-30T20:08:57.286655Z","iopub.execute_input":"2022-04-30T20:08:57.287384Z","iopub.status.idle":"2022-04-30T20:08:57.293249Z","shell.execute_reply.started":"2022-04-30T20:08:57.287337Z","shell.execute_reply":"2022-04-30T20:08:57.292587Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"a, b = pred = model(np.concatenate([x1, x2]))\npred = (a + b)/2\n\nprint('CORRECT')\n\nfor i in range(len(x2)):\n    \n    if np.round(pred[i]) != np.round(y[i]):\n\n        plt.figure(figsize=(10, 5), dpi=400)\n        plt.subplot(1, 2, 1)\n        plt.imshow(x1[i])\n        plt.axis('off')\n        plt.title(f'Pred: {pred[i]}')\n        plt.subplot(1, 2, 2)\n        plt.imshow(x2[i])\n        plt.axis('off')\n        plt.title(f'Truth: {y[i]}')\n        plt.show()\n        plt.close()\n        \n        \n        \nprint('-'*500)\nprint('CORRECT')\n\nfor i in range(len(x2)):\n    \n    if np.round(pred[i]) == np.round(y[i]):\n\n        plt.figure(figsize=(10, 5), dpi=400)\n        plt.subplot(1, 2, 1)\n        plt.imshow(x1[i])\n        plt.axis('off')\n        plt.title(f'Pred: {pred[i]}')\n        plt.subplot(1, 2, 2)\n        plt.imshow(x2[i])\n        plt.axis('off')\n        plt.title(f'Truth: {y[i]}')\n        plt.show()\n        plt.close()","metadata":{"execution":{"iopub.execute_input":"2022-04-30T01:04:46.628144Z","iopub.status.busy":"2022-04-30T01:04:46.627791Z","iopub.status.idle":"2022-04-30T01:05:09.021065Z","shell.execute_reply":"2022-04-30T01:05:09.020286Z","shell.execute_reply.started":"2022-04-30T01:04:46.628107Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]}]}