{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da86beef",
   "metadata": {
    "papermill": {
     "duration": 0.02865,
     "end_time": "2022-04-30T04:44:07.927547",
     "exception": false,
     "start_time": "2022-04-30T04:44:07.898897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DLSM Architecture Translation into TensorFlow - Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb8d8b6",
   "metadata": {
    "papermill": {
     "duration": 0.026175,
     "end_time": "2022-04-30T04:44:07.982914",
     "exception": false,
     "start_time": "2022-04-30T04:44:07.956739",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utility Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a625bd97",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-30T04:44:08.027879Z",
     "iopub.status.busy": "2022-04-30T04:44:08.026405Z",
     "iopub.status.idle": "2022-04-30T04:44:11.915559Z",
     "shell.execute_reply": "2022-04-30T04:44:11.916030Z",
     "shell.execute_reply.started": "2022-04-30T00:31:41.451668Z"
    },
    "papermill": {
     "duration": 3.913622,
     "end_time": "2022-04-30T04:44:11.916287",
     "exception": false,
     "start_time": "2022-04-30T04:44:08.002665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-30 04:44:08--  https://raw.githubusercontent.com/interactive-intelligence/emergent-lang/main/shapedata.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 10989 (11K) [text/plain]\r\n",
      "Saving to: ‘shapedata.py’\r\n",
      "\r\n",
      "shapedata.py        100%[===================>]  10.73K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2022-04-30 04:44:08 (37.5 MB/s) - ‘shapedata.py’ saved [10989/10989]\r\n",
      "\r\n",
      "--2022-04-30 04:44:09--  https://raw.githubusercontent.com/interactive-intelligence/emergent-lang/main/analyzeutil.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 2228 (2.2K) [text/plain]\r\n",
      "Saving to: ‘analyzeutil.py’\r\n",
      "\r\n",
      "analyzeutil.py      100%[===================>]   2.18K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2022-04-30 04:44:10 (29.8 MB/s) - ‘analyzeutil.py’ saved [2228/2228]\r\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'analyzeutil' from '/kaggle/working/analyzeutil.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget -O shapedata.py https://raw.githubusercontent.com/interactive-intelligence/emergent-lang/main/shapedata.py\n",
    "import shapedata\n",
    "import importlib\n",
    "importlib.reload(shapedata)\n",
    "\n",
    "!wget -O analyzeutil.py https://raw.githubusercontent.com/interactive-intelligence/emergent-lang/main/analyzeutil.py\n",
    "import analyzeutil\n",
    "importlib.reload(analyzeutil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ad146",
   "metadata": {
    "papermill": {
     "duration": 0.021786,
     "end_time": "2022-04-30T04:44:11.960571",
     "exception": false,
     "start_time": "2022-04-30T04:44:11.938785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60eba0de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T04:44:12.009671Z",
     "iopub.status.busy": "2022-04-30T04:44:12.009148Z",
     "iopub.status.idle": "2022-04-30T04:44:18.146023Z",
     "shell.execute_reply": "2022-04-30T04:44:18.145137Z",
     "shell.execute_reply.started": "2022-04-30T00:31:44.998619Z"
    },
    "papermill": {
     "duration": 6.163676,
     "end_time": "2022-04-30T04:44:18.146163",
     "exception": false,
     "start_time": "2022-04-30T04:44:11.982487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import layers as L\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f657e2e",
   "metadata": {
    "papermill": {
     "duration": 0.021781,
     "end_time": "2022-04-30T04:44:18.190808",
     "exception": false,
     "start_time": "2022-04-30T04:44:18.169027",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44de14de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T04:44:18.272092Z",
     "iopub.status.busy": "2022-04-30T04:44:18.271299Z",
     "iopub.status.idle": "2022-04-30T04:44:18.273371Z",
     "shell.execute_reply": "2022-04-30T04:44:18.274013Z",
     "shell.execute_reply.started": "2022-04-30T01:08:35.097134Z"
    },
    "papermill": {
     "duration": 0.061477,
     "end_time": "2022-04-30T04:44:18.274141",
     "exception": false,
     "start_time": "2022-04-30T04:44:18.212664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VectorQuantizer(layers.Layer):\n",
    "    def __init__(self, num_embeddings, embedding_dim, beta=0.25, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.beta = (\n",
    "            beta  # This parameter is best kept between [0.25, 2] as per the paper.\n",
    "        )\n",
    "\n",
    "        # Initialize the embeddings which we will quantize.\n",
    "        w_init = tf.random_uniform_initializer()\n",
    "        self.embeddings = tf.Variable(\n",
    "            initial_value=w_init(\n",
    "                shape=(self.embedding_dim, self.num_embeddings), dtype=\"float32\"\n",
    "            ),\n",
    "            trainable=True,\n",
    "            name=\"embeddings_vqvae\",\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        # Calculate the input shape of the inputs and\n",
    "        # then flatten the inputs keeping `embedding_dim` intact.\n",
    "        input_shape = tf.shape(x)\n",
    "        flattened = tf.reshape(x, [-1, self.embedding_dim])\n",
    "\n",
    "        # Quantization.\n",
    "        encoding_indices = self.get_code_indices(flattened)\n",
    "        encodings = tf.one_hot(encoding_indices, self.num_embeddings)\n",
    "        quantized = tf.matmul(encodings, self.embeddings, transpose_b=True)\n",
    "        quantized = tf.reshape(quantized, input_shape)\n",
    "\n",
    "        # Calculate vector quantization loss and add that to the layer. You can learn more\n",
    "        # about adding losses to different layers here:\n",
    "        # https://keras.io/guides/making_new_layers_and_models_via_subclassing/. Check\n",
    "        # the original paper to get a handle on the formulation of the loss function.\n",
    "        commitment_loss = self.beta * tf.reduce_mean(\n",
    "            (tf.stop_gradient(quantized) - x) ** 2\n",
    "        )\n",
    "        codebook_loss = tf.reduce_mean((quantized - tf.stop_gradient(x)) ** 2)\n",
    "        self.add_loss(commitment_loss + codebook_loss)\n",
    "\n",
    "        # Straight-through estimator.\n",
    "        quantized = x + tf.stop_gradient(quantized - x)\n",
    "        return quantized\n",
    "\n",
    "    def get_code_indices(self, flattened_inputs):\n",
    "        # Calculate L2-normalized distance between the inputs and the codes.\n",
    "        similarity = tf.matmul(flattened_inputs, self.embeddings)\n",
    "        distances = (\n",
    "            tf.reduce_sum(flattened_inputs ** 2, axis=1, keepdims=True)\n",
    "            + tf.reduce_sum(self.embeddings ** 2, axis=0)\n",
    "            - 2 * similarity\n",
    "        )\n",
    "\n",
    "        # Derive the indices for minimum distances.\n",
    "        encoding_indices = tf.argmin(distances, axis=1)\n",
    "        return encoding_indices\n",
    "\n",
    "\n",
    "\n",
    "class DLSM(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, \n",
    "                 inp_shape,           # the dimension of the image in three-element tuple form\n",
    "                 seq_len=16,          # number of vectors to form a language sequence\n",
    "                 vocab_size=32,       # number of unique vectors in vector quantizer\n",
    "                 recurrent_units=32,  # number of gru units, also embedding dim for now\n",
    "                 batch_size=32):      # number of samples per batch\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # structural params\n",
    "        self.batch_size = batch_size\n",
    "        self.inp_shape = inp_shape\n",
    "        self.seq_len = seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.recurrent_units = recurrent_units\n",
    "        \n",
    "        # model components\n",
    "        self.vision_module = self.buildVisionModule(inp_shape)\n",
    "        self.speaker = self.buildSpeaker((self.seq_len, 1))\n",
    "        self.quantizer = VectorQuantizer(num_embeddings=self.vocab_size,\n",
    "                                         embedding_dim=self.recurrent_units)\n",
    "        self.listener = self.buildListener((self.seq_len, self.recurrent_units))\n",
    "        \n",
    "        # misc\n",
    "        self.initial_speech = K.variable(value=np.zeros((self.batch_size, self.seq_len, 1)))\n",
    "    \n",
    "    def buildVisionModule(self, inp_shape):\n",
    "        '''\n",
    "        Vision Module - maps images to a vector with length recurrent_units.\n",
    "        '''\n",
    "        \n",
    "        model = keras.models.Sequential(name='Vision_Module')\n",
    "        model.add(L.Input(inp_shape))\n",
    "\n",
    "        model.add(L.Conv2D(16, (2, 5), padding='same'))\n",
    "        model.add(L.LeakyReLU())\n",
    "        model.add(L.Conv2D(16, (2, 5), padding='same'))\n",
    "        model.add(L.LeakyReLU())\n",
    "        model.add(L.Conv2D(16, (2, 2), padding='same'))\n",
    "        model.add(L.LeakyReLU())\n",
    "        model.add(L.MaxPooling2D((2, 2)))\n",
    "\n",
    "        model.add(L.Conv2D(16, (5, 2), padding='same'))\n",
    "        model.add(L.LeakyReLU())\n",
    "        model.add(L.Conv2D(16, (2, 5), padding='same'))\n",
    "        model.add(L.LeakyReLU())\n",
    "        model.add(L.Conv2D(16, (2, 2), padding='same'))\n",
    "        model.add(L.LeakyReLU())\n",
    "        model.add(L.MaxPooling2D((2, 2)))\n",
    "\n",
    "        model.add(L.Flatten())\n",
    "#         model.add(L.Dense(self.recurrent_units, activation='relu'))\n",
    "        model.add(L.Dense(self.recurrent_units, activation='relu'))\n",
    "        model.add(L.BatchNormalization())\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def buildSpeaker(self, inp_shape):\n",
    "        '''\n",
    "        Speaker - takes in initial speech vector and uses image\n",
    "        vector as initial hidden state. Outputs a sequence of vectors\n",
    "        that are quantized.\n",
    "        '''\n",
    "        \n",
    "        init_speech = L.Input(inp_shape)\n",
    "        init_cell = L.Input((self.recurrent_units,))\n",
    "        init_hidden = L.Input((self.recurrent_units,))\n",
    "        lstm1 = L.Bidirectional(L.LSTM(self.recurrent_units, return_sequences=True),\n",
    "                                merge_mode='sum')(init_speech, initial_state=[init_hidden, init_cell,\n",
    "                                                                              init_hidden, init_cell])\n",
    "        lstm2 = L.Bidirectional(L.LSTM(self.recurrent_units, return_sequences=True),\n",
    "                                merge_mode='sum')(lstm1, initial_state=[init_hidden, init_cell,\n",
    "                                                                        init_hidden, init_cell])\n",
    "        \n",
    "        return keras.models.Model(inputs={'init_speech':init_speech, \n",
    "                                          'init_cell':init_cell,\n",
    "                                          'init_hidden':init_hidden},\n",
    "                                  outputs=lstm1)\n",
    "\n",
    "    def buildListener(self, inp_shape):\n",
    "        '''\n",
    "        Listener - takes in the quantized 'language' and outputs a single\n",
    "        scalar probability.\n",
    "        '''\n",
    "        \n",
    "        init_speech = L.Input(inp_shape)\n",
    "        init_cell = L.Input((self.recurrent_units,))\n",
    "        init_hidden = L.Input((self.recurrent_units,))\n",
    "        lstm1 = L.Bidirectional(L.LSTM(self.recurrent_units, return_sequences=True),\n",
    "                                merge_mode='sum')(init_speech, initial_state=[init_hidden, init_cell,\n",
    "                                                                              init_hidden, init_cell])\n",
    "        lstm2 = L.Bidirectional(L.LSTM(self.recurrent_units),\n",
    "                                merge_mode='sum')(lstm1, initial_state=[init_hidden, init_cell,\n",
    "                                                                        init_hidden, init_cell])\n",
    "        \n",
    "        predense = L.Dense(32, activation='relu')(lstm2)\n",
    "        out = L.Dense(1, activation='sigmoid')(predense)\n",
    "        \n",
    "#         init_speech = L.Input(inp_shape)\n",
    "#         init_state = L.Input((self.recurrent_units,))\n",
    "#         gru = L.GRU(self.recurrent_units)(init_speech, initial_state=init_state)\n",
    "#         predense = L.Dense(32, activation='relu')(gru)\n",
    "#         out = L.Dense(1, activation='sigmoid')(predense)\n",
    "        \n",
    "        \n",
    "        return keras.models.Model(inputs=[init_speech, init_cell, init_hidden],\n",
    "                                  outputs=out)\n",
    "    \n",
    "    def get_sequence(self, inputs):\n",
    "        \n",
    "        # split data into half, Yegor-style\n",
    "        half = len(inputs) // 2\n",
    "        xa, xb = inputs[:half], inputs[half:]\n",
    "        \n",
    "        # get vision vectors\n",
    "        vision_a = self.vision_module(xa)\n",
    "        vision_b = self.vision_module(xb)\n",
    "        \n",
    "        # obtain spoken vectors {'init_speech':init_speech, 'init_state':init_state}\n",
    "        spoken_a = self.speaker({'init_speech':self.initial_speech,\n",
    "                                 'init_hidden':tf.random.normal((self.batch_size, self.recurrent_units,)),\n",
    "                                 'init_cell':vision_a})\n",
    "        spoken_b = self.speaker({'init_speech':self.initial_speech,\n",
    "                                 'init_hidden':tf.random.normal((self.batch_size, self.recurrent_units,)),\n",
    "                                 'init_cell':vision_b})\n",
    "        \n",
    "        return spoken_a, spoken_b\n",
    "        \n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        \n",
    "        # split data into half, Yegor-style\n",
    "        half = len(inputs) // 2\n",
    "        xa, xb = inputs[:half], inputs[half:]\n",
    "        \n",
    "        # get vision vectors\n",
    "        vision_a = self.vision_module(xa)\n",
    "        vision_b = self.vision_module(xb)\n",
    "        \n",
    "        # obtain spoken vectors {'init_speech':init_speech, 'init_state':init_state}\n",
    "        spoken_a = self.speaker({'init_speech':self.initial_speech,\n",
    "                                 'init_hidden':tf.random.normal((self.batch_size, self.recurrent_units,)),\n",
    "                                 'init_cell':vision_a})\n",
    "        spoken_b = self.speaker({'init_speech':self.initial_speech,\n",
    "                                 'init_hidden':tf.random.normal((self.batch_size, self.recurrent_units,)),\n",
    "                                 'init_cell':vision_b})\n",
    "        \n",
    "        # quantize speech\n",
    "        quantized_a = self.quantizer(spoken_a)\n",
    "        quantized_b = self.quantizer(spoken_b)\n",
    "        \n",
    "        # obtain output vectors after listening\n",
    "        listened_a = self.listener([quantized_a, vision_b, tf.random.normal((self.batch_size, self.recurrent_units,))])\n",
    "        listened_b = self.listener([quantized_b, vision_a, tf.random.normal((self.batch_size, self.recurrent_units,))])\n",
    "        \n",
    "        return listened_a, listened_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc5f0d",
   "metadata": {
    "papermill": {
     "duration": 0.02158,
     "end_time": "2022-04-30T04:44:18.317408",
     "exception": false,
     "start_time": "2022-04-30T04:44:18.295828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92573e69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T04:44:18.370900Z",
     "iopub.status.busy": "2022-04-30T04:44:18.370248Z",
     "iopub.status.idle": "2022-04-30T04:44:25.107407Z",
     "shell.execute_reply": "2022-04-30T04:44:25.106898Z",
     "shell.execute_reply.started": "2022-04-30T01:55:14.046912Z"
    },
    "papermill": {
     "duration": 6.768488,
     "end_time": "2022-04-30T04:44:25.107530",
     "exception": false,
     "start_time": "2022-04-30T04:44:18.339042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 04:44:18.470390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-30 04:44:18.471509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-30 04:44:18.472187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-30 04:44:18.473146: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-30 04:44:18.474386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-30 04:44:18.475146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-30 04:44:18.475830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-30 04:44:23.047771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-30 04:44:23.048623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-30 04:44:23.049315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-30 04:44:23.049912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14969 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "'''\n",
    "Core data parameters\n",
    "'''\n",
    "BATCH_SIZE = 512\n",
    "SEQ_LEN = 3\n",
    "VOCAB_SIZE = 3\n",
    "RECURRENT_UNITS = 64\n",
    "\n",
    "IMG_DIM = 128\n",
    "MIN_SHAPES = 1\n",
    "MAX_SHAPES = 3\n",
    "SHAPE_TYPES = ['square', 'circle', 'triangle']\n",
    "COLOR_TYPES = [(255,0,0), (0,255,  0), (0,0,255)]\n",
    "OUTLINE = (255, 255, 255)\n",
    "SHAPE_SCALE = 0.2\n",
    "\n",
    "# create dataset\n",
    "data = shapedata.AlecModeShapeData(batch_size=BATCH_SIZE, \n",
    "                                   im_size=IMG_DIM, \n",
    "                                   min_shapes=MIN_SHAPES, \n",
    "                                   max_shapes=MAX_SHAPES,\n",
    "                                   outline = OUTLINE,\n",
    "                                   shape_types = SHAPE_TYPES,\n",
    "                                   shape_colors = COLOR_TYPES,\n",
    "                                   shape_scale = SHAPE_SCALE)\n",
    "\n",
    "# create relevant training artifacts\n",
    "optimizer = tensorflow.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "bce = tensorflow.keras.losses.BinaryCrossentropy()\n",
    "model = DLSM((IMG_DIM, IMG_DIM, 3), \n",
    "             seq_len=SEQ_LEN,\n",
    "             vocab_size=VOCAB_SIZE,\n",
    "             recurrent_units=RECURRENT_UNITS,\n",
    "             batch_size=BATCH_SIZE)\n",
    "\n",
    "# train batch function\n",
    "@tf.function\n",
    "def train_batch(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        half = len(y) // 2\n",
    "        outa, outb = model(x, training=True)\n",
    "        loss = tf.math.divide(tf.math.add(bce(y, outa), bce(y, outb)), 2) # use avg bce as loss\n",
    "#         acc = tf.math.divide(tf.math.add(acc(y, outa), acc(y, outb)), 2)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss, (outa, outb, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b9147ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T04:44:25.161564Z",
     "iopub.status.busy": "2022-04-30T04:44:25.157590Z",
     "iopub.status.idle": "2022-04-30T04:44:25.290832Z",
     "shell.execute_reply": "2022-04-30T04:44:25.291263Z",
     "shell.execute_reply.started": "2022-04-30T01:55:16.991808Z"
    },
    "papermill": {
     "duration": 0.159556,
     "end_time": "2022-04-30T04:44:25.291422",
     "exception": false,
     "start_time": "2022-04-30T04:44:25.131866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=813x560 at 0x7FD08A56FC10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapedata.demo_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f898d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T04:44:25.344584Z",
     "iopub.status.busy": "2022-04-30T04:44:25.343929Z",
     "iopub.status.idle": "2022-04-30T05:08:57.092111Z",
     "shell.execute_reply": "2022-04-30T05:08:57.091582Z"
    },
    "papermill": {
     "duration": 1471.777408,
     "end_time": "2022-04-30T05:08:57.092250",
     "exception": false,
     "start_time": "2022-04-30T04:44:25.314842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 04:44:36.262448: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-30 04:44:38.790336: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH 1999 | Loss: 0.3046955466270447 | Acc: 0.8818359375\r"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score as acc\n",
    "\n",
    "NUM_EPOCHS = 2000\n",
    "\n",
    "losses, accs = [], []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    (x1, x1_shapes), (x2, x2_shapes), y = data.create_batch()\n",
    "    loss, (outa, outb, y) = train_batch(np.concatenate([x1, x2]), np.expand_dims(y,1))\n",
    "    loss = loss.numpy()\n",
    "    accuracy = (acc(np.round(outa), y) + acc(np.round(outb), y))/2\n",
    "    print(f'BATCH {epoch} | Loss: {loss} | Acc: {accuracy}', end = '\\r')\n",
    "    losses.append(loss)\n",
    "    accs.append(accuracy)\n",
    "    \n",
    "# plt.figure(figsize=(10, 5), dpi=400)\n",
    "# plt.plot(losses, color='red')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize=(10, 5), dpi=400)\n",
    "# plt.plot(accs, color='red')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67ff115",
   "metadata": {
    "papermill": {
     "duration": 0.621547,
     "end_time": "2022-04-30T05:08:58.382606",
     "exception": false,
     "start_time": "2022-04-30T05:08:57.761059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```\n",
    "BATCH 1999 | Loss: 0.3106675446033478 | Acc: 0.880859375\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "446437b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T05:08:59.644142Z",
     "iopub.status.busy": "2022-04-30T05:08:59.643327Z",
     "iopub.status.idle": "2022-04-30T05:08:59.681157Z",
     "shell.execute_reply": "2022-04-30T05:08:59.680713Z",
     "shell.execute_reply.started": "2022-04-30T00:57:39.483312Z"
    },
    "papermill": {
     "duration": 0.674519,
     "end_time": "2022-04-30T05:08:59.681274",
     "exception": false,
     "start_time": "2022-04-30T05:08:59.006755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a552d70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T05:09:00.934358Z",
     "iopub.status.busy": "2022-04-30T05:09:00.933542Z",
     "iopub.status.idle": "2022-04-30T05:09:00.935555Z",
     "shell.execute_reply": "2022-04-30T05:09:00.935964Z",
     "shell.execute_reply.started": "2022-04-30T01:02:56.895277Z"
    },
    "papermill": {
     "duration": 0.628899,
     "end_time": "2022-04-30T05:09:00.936101",
     "exception": false,
     "start_time": "2022-04-30T05:09:00.307202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x = np.linspace(-5, 5, 1000)\n",
    "# y = np.sin(x)\n",
    "# plt.plot(x, y)\n",
    "# plt.title('$\\sin x$')\n",
    "# plt.xlabel('time')\n",
    "# plt.ylabel('my iq')\n",
    "# plt.show()\n",
    "\n",
    "# x = np.linspace(-5, 5, 1000)\n",
    "# y = np.sin(x)\n",
    "# plt.figure(dpi=500)\n",
    "# plt.plot(x, y)\n",
    "# plt.title('better plot of $\\sin x$')\n",
    "# plt.xlabel('time')\n",
    "# plt.ylabel('my iq')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a2f223f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T05:09:02.227384Z",
     "iopub.status.busy": "2022-04-30T05:09:02.225954Z",
     "iopub.status.idle": "2022-04-30T05:09:02.302191Z",
     "shell.execute_reply": "2022-04-30T05:09:02.301305Z",
     "shell.execute_reply.started": "2022-04-30T01:03:58.614109Z"
    },
    "papermill": {
     "duration": 0.742651,
     "end_time": "2022-04-30T05:09:02.302310",
     "exception": false,
     "start_time": "2022-04-30T05:09:01.559659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "testdata = shapedata.AlecModeShapeData(batch_size=BATCH_SIZE, \n",
    "                               im_size=IMG_DIM, \n",
    "                               min_shapes=MIN_SHAPES, \n",
    "                               max_shapes=MAX_SHAPES,\n",
    "                               outline = OUTLINE,\n",
    "                               shape_types = SHAPE_TYPES,\n",
    "                               shape_colors = COLOR_TYPES,\n",
    "                               shape_scale = SHAPE_SCALE)\n",
    "(x1, x1_shapes), (x2, x2_shapes), y = testdata.create_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1133ab3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T05:09:03.558494Z",
     "iopub.status.busy": "2022-04-30T05:09:03.557266Z",
     "iopub.status.idle": "2022-04-30T05:09:03.757642Z",
     "shell.execute_reply": "2022-04-30T05:09:03.758716Z",
     "shell.execute_reply.started": "2022-04-30T01:35:51.755525Z"
    },
    "papermill": {
     "duration": 0.833356,
     "end_time": "2022-04-30T05:09:03.758922",
     "exception": false,
     "start_time": "2022-04-30T05:09:02.925566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "speecha, speechb = model.get_sequence(np.concatenate([x1, x2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25e2b790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T05:09:05.051895Z",
     "iopub.status.busy": "2022-04-30T05:09:05.050839Z",
     "iopub.status.idle": "2022-04-30T05:09:05.408027Z",
     "shell.execute_reply": "2022-04-30T05:09:05.407275Z",
     "shell.execute_reply.started": "2022-04-30T01:40:33.086969Z"
    },
    "papermill": {
     "duration": 0.995658,
     "end_time": "2022-04-30T05:09:05.408268",
     "exception": true,
     "start_time": "2022-04-30T05:09:04.412610",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 192 into shape (10,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24/1553926815.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 192 into shape (10,newaxis)"
     ]
    }
   ],
   "source": [
    "model.quantizer.embeddings.numpy().reshape((10, -1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1336d8d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T01:43:57.740638Z",
     "iopub.status.busy": "2022-04-30T01:43:57.739970Z",
     "iopub.status.idle": "2022-04-30T01:43:57.745055Z",
     "shell.execute_reply": "2022-04-30T01:43:57.743637Z",
     "shell.execute_reply.started": "2022-04-30T01:43:57.740602Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d656592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T01:44:59.030774Z",
     "iopub.status.busy": "2022-04-30T01:44:59.030518Z",
     "iopub.status.idle": "2022-04-30T01:44:59.036276Z",
     "shell.execute_reply": "2022-04-30T01:44:59.035587Z",
     "shell.execute_reply.started": "2022-04-30T01:44:59.030743Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.quantizer.embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d6fe5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T01:46:28.337846Z",
     "iopub.status.busy": "2022-04-30T01:46:28.337585Z",
     "iopub.status.idle": "2022-04-30T01:46:28.345155Z",
     "shell.execute_reply": "2022-04-30T01:46:28.344335Z",
     "shell.execute_reply.started": "2022-04-30T01:46:28.337816Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112650fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T01:51:38.317613Z",
     "iopub.status.busy": "2022-04-30T01:51:38.317356Z",
     "iopub.status.idle": "2022-04-30T01:51:38.748953Z",
     "shell.execute_reply": "2022-04-30T01:51:38.748238Z",
     "shell.execute_reply.started": "2022-04-30T01:51:38.317584Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "quant = model.quantizer(speecha)\n",
    "embeddings = model.quantizer.embeddings.numpy().reshape((10, -1))\n",
    "\n",
    "seqs = []\n",
    "for sample in tqdm(range(len(quant))):\n",
    "    seqs.append(model.quantizer.get_code_indices(quant[sample]).numpy())\n",
    "    # seq = []\n",
    "    # for word in quant[sample]:\n",
    "        # seq.append(model.quantizer.get_code_indices(word.numpy()[0]))\n",
    "#         for ind, embedding in enumerate(embeddings):\n",
    "#             if (embedding == word.numpy()).all(): #quant[sample,word]:\n",
    "#                 seq.append(ind)\n",
    "    # seqs.append(seq)\n",
    "    \n",
    "seqs = np.array(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580433c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T01:52:02.660867Z",
     "iopub.status.busy": "2022-04-30T01:52:02.660451Z",
     "iopub.status.idle": "2022-04-30T01:52:02.668836Z",
     "shell.execute_reply": "2022-04-30T01:52:02.667970Z",
     "shell.execute_reply.started": "2022-04-30T01:52:02.660830Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.unique(seqs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf0ea0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T01:52:10.849440Z",
     "iopub.status.busy": "2022-04-30T01:52:10.849184Z",
     "iopub.status.idle": "2022-04-30T01:52:10.855820Z",
     "shell.execute_reply": "2022-04-30T01:52:10.855158Z",
     "shell.execute_reply.started": "2022-04-30T01:52:10.849411Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(np.unique(seqs, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f300b54a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-30T01:04:46.628144Z",
     "iopub.status.busy": "2022-04-30T01:04:46.627791Z",
     "iopub.status.idle": "2022-04-30T01:05:09.021065Z",
     "shell.execute_reply": "2022-04-30T01:05:09.020286Z",
     "shell.execute_reply.started": "2022-04-30T01:04:46.628107Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a, b = pred = model(np.concatenate([x1, x2]))\n",
    "pred = (a + b)/2\n",
    "\n",
    "print('CORRECT')\n",
    "\n",
    "for i in range(len(x2)):\n",
    "    \n",
    "    if np.round(pred[i]) != np.round(y[i]):\n",
    "\n",
    "        plt.figure(figsize=(10, 5), dpi=400)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(x1[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Pred: {pred[i]}')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(x2[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Truth: {y[i]}')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        \n",
    "print('-'*500)\n",
    "print('CORRECT')\n",
    "\n",
    "for i in range(len(x2)):\n",
    "    \n",
    "    if np.round(pred[i]) == np.round(y[i]):\n",
    "\n",
    "        plt.figure(figsize=(10, 5), dpi=400)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(x1[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Pred: {pred[i]}')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(x2[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Truth: {y[i]}')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8973cd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1510.146973,
   "end_time": "2022-04-30T05:09:10.059262",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-30T04:43:59.912289",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
